{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d979d6",
   "metadata": {},
   "source": [
    "# Trying to Semi-Brute Force P(J4,K5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc51415",
   "metadata": {},
   "source": [
    "### Strategy: Find P(J_4, K_5, 8), then increase n by 1 by adding a new vertex in 2^n ways, reducing up to isomorphism, and then checking if it is in P(J_4,K_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403337e",
   "metadata": {},
   "source": [
    "#### imports and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d6ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import permutations, combinations\n",
    "import pynauty as pn\n",
    "import time\n",
    "import gc\n",
    "\n",
    "def powerset(iterable,upper_bound=None, lower_bound=0):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    \"upper bound is the largest cardinality you want your sets to be\"\n",
    "    s = list(iterable)\n",
    "    if upper_bound is not None:\n",
    "      up=upper_bound\n",
    "    else:\n",
    "      up=len(s)\n",
    "    list1=[list(combinations(s, r)) for r in range(lower_bound,up+1)]\n",
    "    list2=[]\n",
    "    for mini in list1:\n",
    "      list2=list2+mini\n",
    "    return list2\n",
    "\n",
    "def max_length(list1):\n",
    "  max1=0\n",
    "  for i in list1:\n",
    "    long=len(i)\n",
    "    if long>max1:\n",
    "      max1=long\n",
    "  return max1\n",
    "\n",
    "def ContainsJ5(graph):\n",
    "  #finds maximal cliques of the graph\n",
    "  all_cliques=list(nx.enumerate_all_cliques(graph))\n",
    "  max_length_cliques=max_length(all_cliques)\n",
    "  if max_length_cliques>4:\n",
    "    #means it contains a k5, so we done\n",
    "    return True\n",
    "  elif max_length_cliques<4:\n",
    "    #too small\n",
    "    return False\n",
    "  elif max_length_cliques==4:\n",
    "    max_cliques=[c for c in all_cliques if len(c)==4]\n",
    "    for cliqueA in max_cliques:\n",
    "      for cliqueB in max_cliques:\n",
    "        #checks if 2 4-cliques are only different by one vertex\n",
    "        union=set(cliqueA).union(set(cliqueB))\n",
    "        if len(union)==5:\n",
    "          return True\n",
    "    return False\n",
    "  else:\n",
    "    print(\"the fuck happened?\")\n",
    "\n",
    "def ContainsJ4(graph):\n",
    "  #finds maximal cliques of the graph\n",
    "  all_cliques=list(nx.enumerate_all_cliques(graph))\n",
    "  max_length_cliques=max_length(all_cliques)\n",
    "  if max_length_cliques>3:\n",
    "    #means it contains a k4, so we done\n",
    "    return True\n",
    "  elif max_length_cliques<3:\n",
    "    #too small, j4 has triangles\n",
    "    return False\n",
    "  elif max_length_cliques==3:\n",
    "    max_cliques=[c for c in all_cliques if len(c)==3]\n",
    "    for cliqueA in max_cliques:\n",
    "      for cliqueB in max_cliques:\n",
    "        #checks if 2 3-cliques are only different by one vertex\n",
    "        union=set(cliqueA).union(set(cliqueB))\n",
    "        if len(union)==4:\n",
    "          return True\n",
    "    return False\n",
    "  else:\n",
    "    print(\"the fuck happened?\")\n",
    "\n",
    "def ContainsJ3(graph):\n",
    "  #finds maximal cliques of the graph\n",
    "  all_cliques=list(nx.enumerate_all_cliques(graph))\n",
    "  max_length_cliques=max_length(all_cliques)\n",
    "  if max_length_cliques>2:\n",
    "    #means it contains a k3, so we done\n",
    "    return True\n",
    "  elif max_length_cliques<2:\n",
    "    #too small\n",
    "    return False\n",
    "  elif max_length_cliques==2:\n",
    "    max_cliques=[c for c in all_cliques if len(c)==2]\n",
    "    for cliqueA in max_cliques:\n",
    "      for cliqueB in max_cliques:\n",
    "        #checks if 2 2-cliques are only different by one vertex\n",
    "        union=set(cliqueA).union(set(cliqueB))\n",
    "        if len(union)==3:\n",
    "          return True\n",
    "    return False\n",
    "  else:\n",
    "    print(\"the fuck happened?\")\n",
    "\n",
    "def convertNetworkXGraph(nx_graph):\n",
    "    pn_graph = pn.Graph(len(nx_graph))\n",
    "    for n in nx_graph:\n",
    "        list_neighbors = []\n",
    "        for nbs in nx_graph[n]:\n",
    "            list_neighbors.append(nbs)\n",
    "        pn_graph.connect_vertex(n, list_neighbors)\n",
    "    return pn_graph\n",
    "\n",
    "def ContainsAntiK5(graph):\n",
    "  max_IS=max_length(list(nx.find_cliques(nx.complement(graph))))\n",
    "  return max_IS>=5\n",
    "\n",
    "def Up_to_isomorphism(list_of_nx_graphs):\n",
    "    #takes a list of nx graphs and removes non-isomorphic copies\n",
    "    Output=[]\n",
    "    hash_set=set()\n",
    "    for nx_graph in list_of_nx_graphs:\n",
    "        pn_graph = convertNetworkXGraph(nx_graph)\n",
    "        cert = pn.certificate(pn_graph)\n",
    "        if cert not in hash_set:\n",
    "            hash_set.add(cert)\n",
    "            Output.append(nx_graph)\n",
    "    return Output\n",
    "\n",
    "def JustPj4k5(list_of_graphs):\n",
    "  #takes in a list of graphs, outputs the ones in Pj4k5\n",
    "  output=[]\n",
    "  for current_graph in list_of_graphs:\n",
    "    if not ContainsJ4(current_graph) and not ContainsAntiK5(current_graph):\n",
    "      output+=[current_graph.copy()]\n",
    "  return output\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "def Write_it_up(n, list1):\n",
    "  #Writes up the things we just found\n",
    "  with open(\"Pj4k5n\"+str(n)+\".txt\",\"wb\") as f:\n",
    "    for graph in list1:\n",
    "      nx.write_graph6(graph,f,header=False) \n",
    "  \n",
    "\n",
    "test_graph=nx.complete_graph(4)\n",
    "test_graph.remove_edge(1,2)\n",
    "print(ContainsJ4(test_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77693fcf",
   "metadata": {},
   "source": [
    "#### (n=1-7) Finding the easy cases \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3f0dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    }
   ],
   "source": [
    "Pj4k5_n1_to_n7=[]\n",
    "#using the graph atlas for 1-7\n",
    "for n in range(1,1253):\n",
    "  #using the graph atlas for 1-7\n",
    "  graph=nx.graph_atlas(n)\n",
    "  if not ContainsAntiK5(graph) and not ContainsJ4(graph):\n",
    "    Pj4k5_n1_to_n7+=[graph.copy()]\n",
    "print(len(Pj4k5_n1_to_n7))\n",
    "\n",
    "with open(\"Pj4k5n1to7.txt\",\"wb\") as f:\n",
    "  for graph in Pj4k5_n1_to_n7:\n",
    "    nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5cb27",
   "metadata": {},
   "source": [
    "#### (n=8) Finding the last easier case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1e04eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12346\n",
      "897\n"
     ]
    }
   ],
   "source": [
    "# import the list of graphs with 8 vertices from txt file\n",
    "Graphs_w_8v=[]\n",
    "Graphs_w_8v=nx.read_graph6(\"Graphs_w_8v_saved.txt\")\n",
    "print(len(Graphs_w_8v))\n",
    "Pj4k5_n8=JustPj4k5(Graphs_w_8v)\n",
    "print(len(Pj4k5_n8))\n",
    "\n",
    "with open(\"Pj4k5n8.txt\",\"wb\") as f:\n",
    "  for graph in Pj4k5_n8:\n",
    "    nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0a567",
   "metadata": {},
   "source": [
    "#### (n=9) Trying the first harder Case "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd926a5",
   "metadata": {},
   "source": [
    "First, some theory behind what I'm doing. I am currently trying to find all of P(J_4, K_5, 9). I have P(J_4, K_5, 8). Notice that if I have a graph G in P(J_4, K_5, 9) and I remove a vertex, then it couldn't have added a J_4 or a Anti-K_5. Thus, this subgraph would be in P(J_4, K_5, 8). This means that if I look at all the ways to add one vertex to every graph in P(J_4, K_5, 8), then we will have a superset of P(J_4, K_5, 9). Then we can just reduce up to isomorphism, and then further reduce by taking out the graphs with a J4 or Anti-K5. And then we stay winning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e279236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 0), (8, 1), (8, 2), (8, 3), (8, 4), (8, 5), (8, 6), (8, 7)]\n",
      "229632\n",
      "74332\n",
      "4463\n"
     ]
    }
   ],
   "source": [
    "#ways to connect the G8 and the new guy\n",
    "n=9\n",
    "Possible_Edges=[(n-1,k) for k in range(n-1)]\n",
    "print(Possible_Edges)\n",
    "G8s_to_check=Pj4k5_n8.copy()\n",
    "combos_to_check=powerset(Possible_Edges)\n",
    "possible_guys=[]\n",
    "for combo in combos_to_check:\n",
    "    for G8 in G8s_to_check:\n",
    "        G9=G8.copy()\n",
    "        G9.add_node(8)\n",
    "        G9.add_edges_from(combo)\n",
    "        possible_guys.append(G9.copy())\n",
    "print(len(possible_guys))\n",
    "\n",
    "possible_unique_guys=Up_to_isomorphism(possible_guys)\n",
    "print(len(possible_unique_guys))\n",
    "\n",
    "Pj4k5_n9=JustPj4k5(possible_unique_guys)\n",
    "print(len(Pj4k5_n9))\n",
    "\n",
    "with open(\"Pj4k5n9.txt\",\"wb\") as f:\n",
    "  for graph in Pj4k5_n9:\n",
    "    nx.write_graph6(graph,f,header=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a98895",
   "metadata": {},
   "source": [
    "#### (n=10) We keep it going "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811268a",
   "metadata": {},
   "source": [
    "Keep the train rolling.\n",
    "\n",
    "Also, in the P(J3, K5) case I did the power set of the possible edges. However, for this vertex v we are adding, the degree has to be less than or equal to 8, so we will ignore the sets that give v more than degree 8.\n",
    "\n",
    "This case gets too hard from the start, bc my computer can't handle the roughly 2 million initial cases before reducing up to isomorphisms. Idea #1: Reduce up to isomorphism as we work. So we hash them in as we run through the 2 million cases, which reduces the amount of set bullshit we have to do. This worked for this case which is good:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41965e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in n=9\n",
    "#restarted the kernel to clear cache\n",
    "Pj4k5_n9=nx.read_graph6(\"Pj4k5n9.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163c29b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4463\n",
      "511\n",
      "1 65589 10.8s per 100,000\n",
      "2 93512 9.5s per 100,000\n",
      "3 142511 9.4s per 100,000\n",
      "4 178531 9.6s per 100,000\n",
      "5 206638 10.3s per 100,000\n",
      "6 234192 10.1s per 100,000\n",
      "7 291281 9.1s per 100,000\n",
      "8 327264 10.8s per 100,000\n",
      "9 365123 9.1s per 100,000\n",
      "10 388710 10.7s per 100,000\n",
      "11 409224 8.9s per 100,000\n",
      "12 456150 9.3s per 100,000\n",
      "13 511567 11.8s per 100,000\n",
      "14 557413 9.1s per 100,000\n",
      "15 598036 13.2s per 100,000\n",
      "16 630672 9.1s per 100,000\n",
      "17 655914 9.1s per 100,000\n",
      "18 731575 16.4s per 100,000\n",
      "19 797141 10.4s per 100,000\n",
      "20 856871 9.7s per 100,000\n",
      "21 914541 9.8s per 100,000\n",
      "22 993469 21.8s per 100,000\n",
      "1056113\n",
      "23577 103.3s to narrow down to P(J4, K5)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n=10\n",
    "Possible_Edges=[(n-1,k) for k in range(n-1)]\n",
    "G9s_to_check=Pj4k5_n9.copy()\n",
    "combos_to_check=powerset(Possible_Edges,upper_bound=8)\n",
    "print(len(G9s_to_check))\n",
    "print(len(combos_to_check))\n",
    "unique_possible_guys=[]\n",
    "hash_set=set()\n",
    "count=0\n",
    "time1=time.time()\n",
    "for combo in combos_to_check:\n",
    "    for G9 in G9s_to_check:\n",
    "        G10=G9.copy()\n",
    "        G10.add_node(n-1)\n",
    "        G10.add_edges_from(combo)\n",
    "        #create the graph, then check if it's unique\n",
    "        pn_graph = convertNetworkXGraph(G10)\n",
    "        cert = pn.certificate(pn_graph)\n",
    "        if cert not in hash_set:\n",
    "            hash_set.add(cert)\n",
    "            unique_possible_guys.append(G10)\n",
    "        count+=1\n",
    "        if count%100000==0:\n",
    "            print(int(count/100000), len(unique_possible_guys),str(int(10*(time.time()-time1))/10) +\"s per 100,000\")\n",
    "            time1=time.time()\n",
    "print(len(unique_possible_guys))\n",
    "time1=time.time()\n",
    "Pj4k5_n10=JustPj4k5(unique_possible_guys)\n",
    "print(len(Pj4k5_n10),str(int(10*(time.time()-time1))/10)+\"s to narrow down to P(J4, K5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf89fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving n=10 in a txt file\n",
    "Write_it_up(10,Pj4k5_n10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515e56c",
   "metadata": {},
   "source": [
    "#### (n=11) We just keep trying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257aaba",
   "metadata": {},
   "source": [
    "n=11,12 are probably going to be the hardest cases because there will be the most cases to deal with. \n",
    "\n",
    "Hopefully the size of P(J4,K5,n) peaks at n=10 or 11\n",
    "\n",
    "Let's see what happens. \n",
    "Trial 1: Didn't go fast enough, and used 8 GB of RAM (I have 8 GB of RAM). The RAM limitations were slowing the computer down a lot. We also have 23 million cases, so we need another way to make the plan better. \n",
    "\n",
    "What if I test if the hash is unique, and if it is, then we test if it is in P(J4, K5, 11). The hash set will make sure we aren't overtesting, and the test if they are in P(J4, K5,11) means we don't store graphs we will just eliminate later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f57422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in n=10\n",
    "#restarted the kernel to clear cache\n",
    "Pj4k5_n10=nx.read_graph6(\"Pj4k5n10.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb647b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23577\n",
      "1013\n",
      "1 775601 39610 306.0s per 1,000,000\n",
      "2 1348431 75537 198.0s per 1,000,000\n",
      "3 1840922 91377 165.4s per 1,000,000\n",
      "4 2156080 96955 138.0s per 1,000,000\n",
      "5 2834179 97570 170.1s per 1,000,000\n",
      "6 3376951 97670 160.3s per 1,000,000\n",
      "7 3895301 97738 156.3s per 1,000,000\n",
      "8 4307494 97771 155.5s per 1,000,000\n",
      "9 4582969 97795 132.8s per 1,000,000\n",
      "10 5313944 97796 180.0s per 1,000,000\n",
      "11 5974853 97796 167.2s per 1,000,000\n",
      "12 6519721 97796 159.4s per 1,000,000\n",
      "13 7100285 97796 160.7s per 1,000,000\n",
      "14 7533774 97796 146.1s per 1,000,000\n",
      "15 7891910 97796 139.5s per 1,000,000\n",
      "16 8740147 97796 197.8s per 1,000,000\n",
      "17 9525363 97796 184.8s per 1,000,000\n",
      "18 10240691 97796 181.2s per 1,000,000\n",
      "19 10971153 97796 198.8s per 1,000,000\n",
      "20 11586118 97796 191.1s per 1,000,000\n",
      "21 12499974 97796 203.1s per 1,000,000\n",
      "22 13356785 97796 199.1s per 1,000,000\n",
      "23 14196397 97796 197.6s per 1,000,000\n",
      "97796\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n=11\n",
    "Possible_Edges=[(n-1,k) for k in range(n-1)]\n",
    "G10s_to_check=Pj4k5_n10.copy()\n",
    "combos_to_check=powerset(Possible_Edges,upper_bound=8)\n",
    "print(len(G10s_to_check))\n",
    "print(len(combos_to_check))\n",
    "Pj4k5_n11=[]\n",
    "hash_set=set()\n",
    "count=0\n",
    "time1=time.time()\n",
    "for combo in combos_to_check:\n",
    "    for G10 in G10s_to_check:\n",
    "        G11=G10.copy()\n",
    "        G11.add_node(n-1)\n",
    "        G11.add_edges_from(combo)\n",
    "        #created the graph, then check if it's unique\n",
    "        pn_graph = convertNetworkXGraph(G11)\n",
    "        cert = pn.certificate(pn_graph)\n",
    "        if cert not in hash_set:\n",
    "            if not ContainsJ4(G11) and not ContainsAntiK5(G11):\n",
    "                #We filter now so we aren't storing too much.\n",
    "                Pj4k5_n11.append(G11)\n",
    "                #fuck it, let's only filter the isomorphic copies of things in the set we want\n",
    "                #this will slow things down, but make it less memory intensive\n",
    "                hash_set.add(cert)\n",
    "        count+=1\n",
    "        if count%1000000==0:\n",
    "            print(int(count/1000000),len(Pj4k5_n11),str(int(10*(time.time()-time1))/10) +\"s per 1,000,000\")\n",
    "            time1=time.time()\n",
    "print(len(Pj4k5_n11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bad771",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write_it_up(11, Pj4k5_n11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf68735",
   "metadata": {},
   "source": [
    "#### (n=12) Can we get 12???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30b48d",
   "metadata": {},
   "source": [
    "I am gonna start by just seeing if I can do what I did last time and see how badly it goes. Although, I do get to have a lower bound on the degree now so that's exciting\n",
    "first run checked 75 mil cases and didn't find a single graph from P(J4, K5). Also took 15 GB of RAM so that crashed my shit. \n",
    "Trial 2: Group the graphs by number of edges, and then we can run through each set of graphs with that many edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89644195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in n=11\n",
    "#restarted the kernel to clear cache\n",
    "Pj4k5_n11=nx.read_graph6(\"Pj4k5n11.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd97610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n"
     ]
    }
   ],
   "source": [
    "#Sort Pj4k5_n11 by edge count\n",
    "\n",
    "#First, we need to identify the possible edge counts for n=11\n",
    "eleven_hash=set()\n",
    "for graph in Pj4k5_n11:\n",
    "    edge_count=len(graph.edges())\n",
    "    if edge_count not in eleven_hash:\n",
    "        eleven_hash.add(edge_count)\n",
    "print(eleven_hash)\n",
    "#Next, we sort into a dictionary by edge count\n",
    "Pj4k5_n11_dict={k:[] for k in eleven_hash}\n",
    "for graph in Pj4k5_n11:\n",
    "    k=len(graph.edges())\n",
    "    Pj4k5_n11_dict[k].append(graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c136e590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{11: [(10, 1)], 12: [(10, 2), (11, 1)], 13: [(10, 3), (11, 2), (12, 1)], 14: [(10, 4), (11, 3), (12, 2), (13, 1)], 15: [(10, 5), (11, 4), (12, 3), (13, 2), (14, 1)], 16: [(10, 6), (11, 5), (12, 4), (13, 3), (14, 2), (15, 1)], 17: [(10, 7), (11, 6), (12, 5), (13, 4), (14, 3), (15, 2), (16, 1)], 18: [(10, 8), (11, 7), (12, 6), (13, 5), (14, 4), (15, 3), (16, 2), (17, 1)], 19: [(11, 8), (12, 7), (13, 6), (14, 5), (15, 4), (16, 3), (17, 2), (18, 1)], 20: [(12, 8), (13, 7), (14, 6), (15, 5), (16, 4), (17, 3), (18, 2), (19, 1)], 21: [(13, 8), (14, 7), (15, 6), (16, 5), (17, 4), (18, 3), (19, 2), (20, 1)], 22: [(14, 8), (15, 7), (16, 6), (17, 5), (18, 4), (19, 3), (20, 2), (21, 1)], 23: [(15, 8), (16, 7), (17, 6), (18, 5), (19, 4), (20, 3), (21, 2), (22, 1)], 24: [(16, 8), (17, 7), (18, 6), (19, 5), (20, 4), (21, 3), (22, 2), (23, 1)], 25: [(17, 8), (18, 7), (19, 6), (20, 5), (21, 4), (22, 3), (23, 2), (24, 1)], 26: [(18, 8), (19, 7), (20, 6), (21, 5), (22, 4), (23, 3), (24, 2), (25, 1)], 27: [(19, 8), (20, 7), (21, 6), (22, 5), (23, 4), (24, 3), (25, 2)], 28: [(20, 8), (21, 7), (22, 6), (23, 5), (24, 4), (25, 3)], 29: [(21, 8), (22, 7), (23, 6), (24, 5), (25, 4)], 30: [(22, 8), (23, 7), (24, 6), (25, 5)], 31: [(23, 8), (24, 7), (25, 6)], 32: [(24, 8), (25, 7)], 33: [(25, 8)]}\n",
      "11 11\n",
      "12 88\n",
      "13 462\n",
      "14 2024\n",
      "15 8162\n",
      "16 31526\n",
      "17 116490\n",
      "18 401918\n",
      "19 1247136\n",
      "20 3361402\n",
      "21 7695952\n",
      "22 14797233\n",
      "23 23747603\n",
      "24 31672927\n",
      "25 34941445\n",
      "26 31630830\n",
      "27 23113552\n",
      "28 13212573\n",
      "29 5623365\n",
      "30 1669239\n",
      "31 321882\n",
      "32 37620\n",
      "33 2640\n"
     ]
    }
   ],
   "source": [
    "#Now, sort the powerset by how many edges it adds to the G12\n",
    "n=12\n",
    "Possible_Edges=[(n-1,k) for k in range(n-1)]\n",
    "powerset12=powerset(Possible_Edges,upper_bound=8,lower_bound=1)\n",
    "#sort into a dictionary by # of edges added\n",
    "powerset_dict={k:[] for k in range(1,9)} \n",
    "for edges in powerset12:\n",
    "    powerset_dict[len(edges)].append(edges)\n",
    "\n",
    "#There are 10-25 graphs in the G11, and 1-8 being added, so we will be checking graphs with 11 to 33 edges\n",
    "#for each possible number n for e(G12), we will only check graphs constructed with numbers that sum to n\n",
    "\n",
    "#Now, for each possible edge count for a G12, we will make a list of tuples \n",
    "# that indicated what combos add to that edge count\n",
    "#so for 11 we have [(10,1)], for 12 we have [(10,2),(11,1)], etc\n",
    "combos_dict={k:[] for k in range(11,34)}\n",
    "for G11_size in eleven_hash:\n",
    "    for edges_size in range(1,9):\n",
    "        combos_dict[G11_size+edges_size].append((G11_size,edges_size))\n",
    "\n",
    "print(combos_dict)\n",
    "\n",
    "#Counting which cases will be the worst to do\n",
    "for k in combos_dict:\n",
    "    count3=0\n",
    "    for tuple in combos_dict[k]:\n",
    "        count3+=len(Pj4k5_n11_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "    print(k,count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02623478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 11 edges\n",
      "We have  11 graphs to check\n",
      "(10, 1)\n",
      "done with graphs with 11 edges\n",
      "11 graphs completed in 0.0 seconds\n",
      "2 unique graphs checked\n",
      "11 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,12) found: 0\n",
      "\n",
      "Now checking graphs with 12 edges\n",
      "We have  88 graphs to check\n",
      "(10, 2)\n",
      "(11, 1)\n",
      "done with graphs with 12 edges\n",
      "88 graphs completed in 0.0 seconds\n",
      "14 unique graphs checked\n",
      "99 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,12) found: 1\n",
      "\n",
      "Now checking graphs with 13 edges\n",
      "We have  462 graphs to check\n",
      "(10, 3)\n",
      "(11, 2)\n",
      "(12, 1)\n",
      "done with graphs with 13 edges\n",
      "462 graphs completed in 0.1 seconds\n",
      "84 unique graphs checked\n",
      "561 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,12) found: 2\n",
      "\n",
      "Now checking graphs with 14 edges\n",
      "We have  2024 graphs to check\n",
      "(10, 4)\n",
      "(11, 3)\n",
      "(12, 2)\n",
      "(13, 1)\n",
      "done with graphs with 14 edges\n",
      "2024 graphs completed in 0.7 seconds\n",
      "483 unique graphs checked\n",
      "2585 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,12) found: 6\n",
      "\n",
      "Now checking graphs with 15 edges\n",
      "We have  8162 graphs to check\n",
      "(10, 5)\n",
      "(11, 4)\n",
      "(12, 3)\n",
      "(13, 2)\n",
      "(14, 1)\n",
      "done with graphs with 15 edges\n",
      "8162 graphs completed in 2.8 seconds\n",
      "2557 unique graphs checked\n",
      "10747 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,12) found: 20\n",
      "\n",
      "Now checking graphs with 16 edges\n",
      "We have  31526 graphs to check\n",
      "(10, 6)\n",
      "(11, 5)\n",
      "(12, 4)\n",
      "(13, 3)\n",
      "(14, 2)\n",
      "(15, 1)\n",
      "done with graphs with 16 edges\n",
      "31526 graphs completed in 9.3 seconds\n",
      "12419 unique graphs checked\n",
      "42273 graphs total completed in 0.2 minutes\n",
      "Total in P(J4,K5,12) found: 65\n",
      "\n",
      "Now checking graphs with 17 edges\n",
      "We have  116490 graphs to check\n",
      "(10, 7)\n",
      "(11, 6)\n",
      "(12, 5)\n",
      "(13, 4)\n",
      "(14, 3)\n",
      "(15, 2)\n",
      "(16, 1)\n",
      "done with graphs with 17 edges\n",
      "116490 graphs completed in 40.6 seconds\n",
      "54856 unique graphs checked\n",
      "158763 graphs total completed in 0.8 minutes\n",
      "Total in P(J4,K5,12) found: 215\n",
      "\n",
      "Now checking graphs with 18 edges\n",
      "We have  401918 graphs to check\n",
      "(10, 8)\n",
      "(11, 7)\n",
      "(12, 6)\n",
      "(13, 5)\n",
      "(14, 4)\n",
      "(15, 3)\n",
      "(16, 2)\n",
      "(17, 1)\n",
      "done with graphs with 18 edges\n",
      "401918 graphs completed in 106.4 seconds\n",
      "214248 unique graphs checked\n",
      "560681 graphs total completed in 2.6 minutes\n",
      "Total in P(J4,K5,12) found: 724\n",
      "\n",
      "Now checking graphs with 19 edges\n",
      "We have  1247136 graphs to check\n",
      "(11, 8)\n",
      "(12, 7)\n",
      "(13, 6)\n",
      "(14, 5)\n",
      "(15, 4)\n",
      "(16, 3)\n",
      "(17, 2)\n",
      "(18, 1)\n",
      "done with graphs with 19 edges\n",
      "1247136 graphs completed in 331.7 seconds\n",
      "711797 unique graphs checked\n",
      "1807817 graphs total completed in 8.2 minutes\n",
      "Total in P(J4,K5,12) found: 2327\n",
      "\n",
      "Now checking graphs with 20 edges\n",
      "We have  3361402 graphs to check\n",
      "(12, 8)\n",
      "(13, 7)\n",
      "(14, 6)\n",
      "(15, 5)\n",
      "(16, 4)\n",
      "(17, 3)\n",
      "(18, 2)\n",
      "(19, 1)\n",
      "done with graphs with 20 edges\n",
      "3361402 graphs completed in 847.9 seconds\n",
      "1972314 unique graphs checked\n",
      "5169219 graphs total completed in 22.3 minutes\n",
      "Total in P(J4,K5,12) found: 7265\n",
      "\n",
      "Now checking graphs with 21 edges\n",
      "We have  7695952 graphs to check\n",
      "(13, 8)\n",
      "(14, 7)\n",
      "(15, 6)\n",
      "(16, 5)\n",
      "(17, 4)\n",
      "(18, 3)\n",
      "(19, 2)\n",
      "(20, 1)\n",
      "done with graphs with 21 edges\n",
      "7695952 graphs completed in 1782.9 seconds\n",
      "4601349 unique graphs checked\n",
      "12865171 graphs total completed in 52.0 minutes\n",
      "Total in P(J4,K5,12) found: 20814\n",
      "\n",
      "Now checking graphs with 22 edges\n",
      "We have  14797233 graphs to check\n",
      "(14, 8)\n",
      "(15, 7)\n",
      "(16, 6)\n",
      "(17, 5)\n",
      "(18, 4)\n",
      "(19, 3)\n",
      "(20, 2)\n",
      "(21, 1)\n",
      "done with graphs with 22 edges\n",
      "14797233 graphs completed in 3028.2 seconds\n",
      "9207245 unique graphs checked\n",
      "27662404 graphs total completed in 102.5 minutes\n",
      "Total in P(J4,K5,12) found: 50048\n",
      "\n",
      "Now checking graphs with 23 edges\n",
      "We have  23747603 graphs to check\n",
      "(15, 8)\n",
      "(16, 7)\n",
      "(17, 6)\n",
      "(18, 5)\n",
      "(19, 4)\n",
      "(20, 3)\n",
      "(21, 2)\n",
      "(22, 1)\n",
      "done with graphs with 23 edges\n",
      "23747603 graphs completed in 4914.8 seconds\n",
      "15861075 unique graphs checked\n",
      "51410007 graphs total completed in 184.4 minutes\n",
      "Total in P(J4,K5,12) found: 94414\n",
      "\n",
      "Now checking graphs with 24 edges\n",
      "We have  31672927 graphs to check\n",
      "(16, 8)\n",
      "(17, 7)\n",
      "(18, 6)\n",
      "(19, 5)\n",
      "(20, 4)\n",
      "(21, 3)\n",
      "(22, 2)\n",
      "(23, 1)\n",
      "done with graphs with 24 edges\n",
      "31672927 graphs completed in 6420.2 seconds\n",
      "23191388 unique graphs checked\n",
      "83082934 graphs total completed in 291.5 minutes\n",
      "Total in P(J4,K5,12) found: 138743\n",
      "\n",
      "Now checking graphs with 25 edges\n",
      "We have  34941445 graphs to check\n",
      "(17, 8)\n",
      "(18, 7)\n",
      "(19, 6)\n",
      "(20, 5)\n",
      "(21, 4)\n",
      "(22, 3)\n",
      "(23, 2)\n",
      "(24, 1)\n",
      "done with graphs with 25 edges\n",
      "34941445 graphs completed in 7646.7 seconds\n",
      "28122990 unique graphs checked\n",
      "118024379 graphs total completed in 419.3 minutes\n",
      "Total in P(J4,K5,12) found: 166816\n",
      "\n",
      "Now checking graphs with 26 edges\n",
      "We have  31630830 graphs to check\n",
      "(18, 8)\n",
      "(19, 7)\n",
      "(20, 6)\n",
      "(21, 5)\n",
      "(22, 4)\n",
      "(23, 3)\n",
      "(24, 2)\n",
      "(25, 1)\n",
      "done with graphs with 26 edges\n",
      "31630830 graphs completed in 8489.8 seconds\n",
      "27544067 unique graphs checked\n",
      "149655209 graphs total completed in 561.6 minutes\n",
      "Total in P(J4,K5,12) found: 177816\n",
      "\n",
      "Now checking graphs with 27 edges\n",
      "We have  23113552 graphs to check\n",
      "(19, 8)\n",
      "(20, 7)\n",
      "(21, 6)\n",
      "(22, 5)\n",
      "(23, 4)\n",
      "(24, 3)\n",
      "(25, 2)\n",
      "done with graphs with 27 edges\n",
      "23113552 graphs completed in 5521.1 seconds\n",
      "21188028 unique graphs checked\n",
      "172768761 graphs total completed in 660.5 minutes\n",
      "Total in P(J4,K5,12) found: 180415\n",
      "\n",
      "Now checking graphs with 28 edges\n",
      "We have  13212573 graphs to check\n",
      "(20, 8)\n",
      "(21, 7)\n",
      "(22, 6)\n",
      "(23, 5)\n",
      "(24, 4)\n",
      "(25, 3)\n",
      "done with graphs with 28 edges\n",
      "13212573 graphs completed in 3298.3 seconds\n",
      "12395538 unique graphs checked\n",
      "185981334 graphs total completed in 715.7 minutes\n",
      "Total in P(J4,K5,12) found: 180780\n",
      "\n",
      "Now checking graphs with 29 edges\n",
      "We have  5623365 graphs to check\n",
      "(21, 8)\n",
      "(22, 7)\n",
      "(23, 6)\n",
      "(24, 5)\n",
      "(25, 4)\n",
      "done with graphs with 29 edges\n",
      "5623365 graphs completed in 1321.7 seconds\n",
      "5275564 unique graphs checked\n",
      "191604699 graphs total completed in 738.2 minutes\n",
      "Total in P(J4,K5,12) found: 180809\n",
      "\n",
      "Now checking graphs with 30 edges\n",
      "We have  1669239 graphs to check\n",
      "(22, 8)\n",
      "(23, 7)\n",
      "(24, 6)\n",
      "(25, 5)\n",
      "done with graphs with 30 edges\n",
      "1669239 graphs completed in 391.7 seconds\n",
      "1532470 unique graphs checked\n",
      "193273938 graphs total completed in 744.8 minutes\n",
      "Total in P(J4,K5,12) found: 180813\n",
      "\n",
      "Now checking graphs with 31 edges\n",
      "We have  321882 graphs to check\n",
      "(23, 8)\n",
      "(24, 7)\n",
      "(25, 6)\n",
      "done with graphs with 31 edges\n",
      "321882 graphs completed in 74.9 seconds\n",
      "278143 unique graphs checked\n",
      "193595820 graphs total completed in 746.0 minutes\n",
      "Total in P(J4,K5,12) found: 180813\n",
      "\n",
      "Now checking graphs with 32 edges\n",
      "We have  37620 graphs to check\n",
      "(24, 8)\n",
      "(25, 7)\n",
      "done with graphs with 32 edges\n",
      "37620 graphs completed in 8.5 seconds\n",
      "27763 unique graphs checked\n",
      "193633440 graphs total completed in 746.2 minutes\n",
      "Total in P(J4,K5,12) found: 180813\n",
      "\n",
      "Now checking graphs with 33 edges\n",
      "We have  2640 graphs to check\n",
      "(25, 8)\n",
      "done with graphs with 33 edges\n",
      "2640 graphs completed in 0.5 seconds\n",
      "1191 unique graphs checked\n",
      "193636080 graphs total completed in 746.2 minutes\n",
      "Total in P(J4,K5,12) found: 180813\n"
     ]
    }
   ],
   "source": [
    "#run through 11-33\n",
    "Pj4k5_n12=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "for k in combos_dict:\n",
    "    print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "    #grab all pairs i,j that add to k\n",
    "    combos_to_check=combos_dict[k]\n",
    "    hash_set_k=set()\n",
    "    time1=time.time()\n",
    "    #counts the number of graphs with k vertices checked\n",
    "    k_count=0\n",
    "    How_many_to_check=0\n",
    "    for tuple in combos_to_check:\n",
    "        How_many_to_check+=len(Pj4k5_n11_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "    print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "    for tuple in combos_to_check:\n",
    "        #all G11s with the desired i value\n",
    "        print(tuple)\n",
    "        G11s_to_check=Pj4k5_n11_dict[tuple[0]]\n",
    "        #all edge sets with the desired j value\n",
    "        edge_combos=powerset_dict[tuple[1]]\n",
    "        #iterate through all combos of them\n",
    "        for edges in edge_combos:\n",
    "            for G11 in G11s_to_check:\n",
    "                #create the graph\n",
    "                G12=G11.copy()\n",
    "                G12.add_node(n-1)\n",
    "                G12.add_edges_from(edges)\n",
    "                #count how many we checked\n",
    "                count+=1\n",
    "                k_count+=1\n",
    "                pn_graph = convertNetworkXGraph(G12)\n",
    "                cert = pn.certificate(pn_graph)\n",
    "                if cert not in hash_set_k:\n",
    "                    #if not already checked, add it and check if it is in J4 K5\n",
    "                    hash_set_k.add(cert)\n",
    "                    if not ContainsJ4(G12) and not ContainsAntiK5(G12):\n",
    "                        #We store if it is in the magical set we are trying to find\n",
    "                        Pj4k5_n12.append(G12)\n",
    "    elapsedk=time.time()-time1\n",
    "    elapsedtotal=time.time()-start_time\n",
    "    print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "    print(str(k_count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "    print(str(len(hash_set_k))+\" unique graphs checked\")\n",
    "    print(str(count)+\" graphs total completed in \"+ str(int(elapsedtotal/6)/10)+\" minutes\")\n",
    "    print(\"Total in P(J4,K5,12) found:\",len(Pj4k5_n12))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20130d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving this bs\n",
    "Write_it_up(12,Pj4k5_n12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad59e11",
   "metadata": {},
   "source": [
    "#### (n=13) Oh dear. Let's make it happen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45591832",
   "metadata": {},
   "source": [
    "This is probably going to be the worst case (fr this time) because we have a lot of graphs to check. \n",
    "3784 edge combos\n",
    "180813 G12s to check\n",
    "684,196,392 graphs to check \n",
    "\n",
    "edge cases: 14 edges to 38 edges\n",
    "\n",
    "Added a specific garbage collector call to make it speed up a little bit.\n",
    "\n",
    "Took on the n=14-25 cases first and stored them, because they are too small to give me real issues. \n",
    "\n",
    "For n=26,27,28,29,30,31,32, I will have a helluva time calculating everything. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438bcc58",
   "metadata": {},
   "source": [
    "##### Run these 3 cells before each edge case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d076a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in n=12\n",
    "#restarted the kernel to clear cache\n",
    "Pj4k5_n12=nx.read_graph6(\"Pj4k5n12.txt\")\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7002fc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}\n"
     ]
    }
   ],
   "source": [
    "#Sort Pj4k5_n12 by edge count\n",
    "\n",
    "#First, we need to identify the possible edge counts for n=12\n",
    "twelve_hash=set()\n",
    "#Also find the \n",
    "for graph in Pj4k5_n12:\n",
    "    edge_count=len(graph.edges())\n",
    "    if edge_count not in twelve_hash:\n",
    "        twelve_hash.add(edge_count)\n",
    "print(twelve_hash)\n",
    "#Next, we sort into a dictionary by edge count\n",
    "Pj4k5_n12_dict={k:[] for k in twelve_hash}\n",
    "for graph in Pj4k5_n12:\n",
    "    k=len(graph.edges())\n",
    "    Pj4k5_n12_dict[k].append(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465b39bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{14: [(12, 2)], 15: [(12, 3), (13, 2)], 16: [(12, 4), (13, 3), (14, 2)], 17: [(12, 5), (13, 4), (14, 3), (15, 2)], 18: [(12, 6), (13, 5), (14, 4), (15, 3), (16, 2)], 19: [(12, 7), (13, 6), (14, 5), (15, 4), (16, 3), (17, 2)], 20: [(12, 8), (13, 7), (14, 6), (15, 5), (16, 4), (17, 3), (18, 2)], 21: [(13, 8), (14, 7), (15, 6), (16, 5), (17, 4), (18, 3), (19, 2)], 22: [(14, 8), (15, 7), (16, 6), (17, 5), (18, 4), (19, 3), (20, 2)], 23: [(15, 8), (16, 7), (17, 6), (18, 5), (19, 4), (20, 3), (21, 2)], 24: [(16, 8), (17, 7), (18, 6), (19, 5), (20, 4), (21, 3), (22, 2)], 25: [(17, 8), (18, 7), (19, 6), (20, 5), (21, 4), (22, 3), (23, 2)], 26: [(18, 8), (19, 7), (20, 6), (21, 5), (22, 4), (23, 3), (24, 2)], 27: [(19, 8), (20, 7), (21, 6), (22, 5), (23, 4), (24, 3), (25, 2)], 28: [(20, 8), (21, 7), (22, 6), (23, 5), (24, 4), (25, 3), (26, 2)], 29: [(21, 8), (22, 7), (23, 6), (24, 5), (25, 4), (26, 3), (27, 2)], 30: [(22, 8), (23, 7), (24, 6), (25, 5), (26, 4), (27, 3), (28, 2)], 31: [(23, 8), (24, 7), (25, 6), (26, 5), (27, 4), (28, 3), (29, 2)], 32: [(24, 8), (25, 7), (26, 6), (27, 5), (28, 4), (29, 3), (30, 2)], 33: [(25, 8), (26, 7), (27, 6), (28, 5), (29, 4), (30, 3)], 34: [(26, 8), (27, 7), (28, 6), (29, 5), (30, 4)], 35: [(27, 8), (28, 7), (29, 6), (30, 5)], 36: [(28, 8), (29, 7), (30, 6)], 37: [(29, 8), (30, 7)], 38: [(30, 8)]}\n",
      "14 66\n",
      "15 286\n",
      "16 979\n",
      "17 3091\n",
      "18 9746\n",
      "19 31614\n",
      "20 104940\n",
      "21 344267\n",
      "22 1103971\n",
      "23 3358377\n",
      "24 9235501\n",
      "25 21935837\n",
      "26 43972115\n",
      "27 73943353\n",
      "28 104170121\n",
      "29 122450504\n",
      "30 118843384\n",
      "31 93089909\n",
      "32 56586398\n",
      "33 25313926\n",
      "34 7865616\n",
      "35 1605549\n",
      "36 207339\n",
      "37 17523\n",
      "38 1980\n"
     ]
    }
   ],
   "source": [
    "#Now, sort the powerset by how many edges it adds to the G13\n",
    "n=13\n",
    "Possible_Edges=[(n-1,k) for k in range(n-1)]\n",
    "#lower bound is now 2\n",
    "powerset12=powerset(Possible_Edges,upper_bound=8,lower_bound=2)\n",
    "#sort into a dictionary by # of edges added\n",
    "powerset_dict={k:[] for k in range(2,9)} \n",
    "for edges in powerset12:\n",
    "    powerset_dict[len(edges)].append(edges)\n",
    "\n",
    "#There are 12-30 edged graphs in the G12, and 2-8 being added, so we will be checking graphs with 14 to 38 edges\n",
    "#for each possible number n for e(G13), we will only check graphs constructed with numbers that sum to n\n",
    "\n",
    "#Now, for each possible edge count for a G13, we will make a list of tuples \n",
    "# that indicated what combos add to that edge count\n",
    "#so for 14 we have [(12,2)], for 15 we have [(13,2),(12,3)], etc\n",
    "combos_dict={k:[] for k in range(14,39)}\n",
    "for G12_size in twelve_hash:\n",
    "    for edges_size in range(2,9):\n",
    "        combos_dict[G12_size+edges_size].append((G12_size,edges_size))\n",
    "\n",
    "print(combos_dict)\n",
    "\n",
    "#Counting which cases will be the worst to do\n",
    "for k in combos_dict:\n",
    "    count3=0\n",
    "    for tuple in combos_dict[k]:\n",
    "        count3+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "    print(k,count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ad585",
   "metadata": {},
   "source": [
    "##### I need to run through 14-38, but it would perhaps be easier to run through some of the faster cases before tackling the hard cases (26-32). So first I'm gonna run 14-25, then try and tackle the worse cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a5374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 14 edges\n",
      "We have 66 graphs to check\n",
      "(12, 2)\n",
      "done with graphs with 14 edges\n",
      "66 graphs completed in 0.0 seconds\n",
      "2 unique graphs checked\n",
      "66 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,13) found: 0\n",
      "\n",
      "Now checking graphs with 15 edges\n",
      "We have 286 graphs to check\n",
      "(12, 3)\n",
      "(13, 2)\n",
      "done with graphs with 15 edges\n",
      "286 graphs completed in 0.0 seconds\n",
      "11 unique graphs checked\n",
      "352 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,13) found: 0\n",
      "\n",
      "Now checking graphs with 16 edges\n",
      "We have 979 graphs to check\n",
      "(12, 4)\n",
      "(13, 3)\n",
      "(14, 2)\n",
      "done with graphs with 16 edges\n",
      "979 graphs completed in 0.1 seconds\n",
      "65 unique graphs checked\n",
      "1331 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,13) found: 0\n",
      "\n",
      "Now checking graphs with 17 edges\n",
      "We have 3091 graphs to check\n",
      "(12, 5)\n",
      "(13, 4)\n",
      "(14, 3)\n",
      "(15, 2)\n",
      "done with graphs with 17 edges\n",
      "3091 graphs completed in 1.2 seconds\n",
      "366 unique graphs checked\n",
      "4422 graphs total completed in 0.1 minutes\n",
      "Total in P(J4,K5,13) found: 0\n",
      "\n",
      "Now checking graphs with 18 edges\n",
      "We have 9746 graphs to check\n",
      "(12, 6)\n",
      "(13, 5)\n",
      "(14, 4)\n",
      "(15, 3)\n",
      "(16, 2)\n",
      "done with graphs with 18 edges\n",
      "9746 graphs completed in 3.7 seconds\n",
      "1974 unique graphs checked\n",
      "14168 graphs total completed in 0.1 minutes\n",
      "Total in P(J4,K5,13) found: 0\n",
      "\n",
      "Now checking graphs with 19 edges\n",
      "We have 31614 graphs to check\n",
      "(12, 7)\n",
      "(13, 6)\n",
      "(14, 5)\n",
      "(15, 4)\n",
      "(16, 3)\n",
      "(17, 2)\n",
      "done with graphs with 19 edges\n",
      "31614 graphs completed in 11.5 seconds\n",
      "9746 unique graphs checked\n",
      "45782 graphs total completed in 0.3 minutes\n",
      "Total in P(J4,K5,13) found: 0\n",
      "\n",
      "Now checking graphs with 20 edges\n",
      "We have 104940 graphs to check\n",
      "(12, 8)\n",
      "(13, 7)\n",
      "(14, 6)\n",
      "(15, 5)\n",
      "(16, 4)\n",
      "(17, 3)\n",
      "(18, 2)\n",
      "done with graphs with 20 edges\n",
      "104940 graphs completed in 49.0 seconds\n",
      "44149 unique graphs checked\n",
      "150722 graphs total completed in 1.2 minutes\n",
      "Total in P(J4,K5,13) found: 0\n",
      "\n",
      "Now checking graphs with 21 edges\n",
      "We have 344267 graphs to check\n",
      "(13, 8)\n",
      "(14, 7)\n",
      "(15, 6)\n",
      "(16, 5)\n",
      "(17, 4)\n",
      "(18, 3)\n",
      "(19, 2)\n",
      "done with graphs with 21 edges\n",
      "344267 graphs completed in 141.9 seconds\n",
      "182845 unique graphs checked\n",
      "494989 graphs total completed in 3.6 minutes\n",
      "Total in P(J4,K5,13) found: 1\n",
      "\n",
      "Now checking graphs with 22 edges\n",
      "We have 1103971 graphs to check\n",
      "(14, 8)\n",
      "(15, 7)\n",
      "(16, 6)\n",
      "(17, 5)\n",
      "(18, 4)\n",
      "(19, 3)\n",
      "(20, 2)\n",
      "done with graphs with 22 edges\n",
      "1103971 graphs completed in 385.1 seconds\n",
      "695929 unique graphs checked\n",
      "1598960 graphs total completed in 10.0 minutes\n",
      "Total in P(J4,K5,13) found: 7\n",
      "\n",
      "Now checking graphs with 23 edges\n",
      "We have 3358377 graphs to check\n",
      "(15, 8)\n",
      "(16, 7)\n",
      "(17, 6)\n",
      "(18, 5)\n",
      "(19, 4)\n",
      "(20, 3)\n",
      "(21, 2)\n",
      "done with graphs with 23 edges\n",
      "3358377 graphs completed in 1106.5 seconds\n",
      "2382577 unique graphs checked\n",
      "4957337 graphs total completed in 28.5 minutes\n",
      "Total in P(J4,K5,13) found: 43\n",
      "\n",
      "Now checking graphs with 24 edges\n",
      "We have 9235501 graphs to check\n",
      "(16, 8)\n",
      "(17, 7)\n",
      "(18, 6)\n",
      "(19, 5)\n",
      "(20, 4)\n",
      "(21, 3)\n",
      "(22, 2)\n",
      "done with graphs with 24 edges\n",
      "9235501 graphs completed in 2751.6 seconds\n",
      "7033429 unique graphs checked\n",
      "14192838 graphs total completed in 74.4 minutes\n",
      "Total in P(J4,K5,13) found: 288\n",
      "\n",
      "Now checking graphs with 25 edges\n",
      "We have 21935837 graphs to check\n",
      "(17, 8)\n",
      "(18, 7)\n",
      "(19, 6)\n",
      "(20, 5)\n",
      "(21, 4)\n",
      "(22, 3)\n",
      "(23, 2)\n",
      "done with graphs with 25 edges\n",
      "21935837 graphs completed in 6143.8 seconds\n",
      "17372209 unique graphs checked\n",
      "36128675 graphs total completed in 176.8 minutes\n",
      "Total in P(J4,K5,13) found: 1479\n"
     ]
    }
   ],
   "source": [
    "#run through 14-25\n",
    "Pj4k5_n13=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "for k in range(14,26):\n",
    "    print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "    #grab all pairs i,j that add to k\n",
    "    combos_to_check=combos_dict[k]\n",
    "    hash_set_k=set()\n",
    "    time1=time.time()\n",
    "    #counts the number of graphs with k vertices checked\n",
    "    k_count=0\n",
    "    How_many_to_check=0\n",
    "    for tuple in combos_to_check:\n",
    "        How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "    print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "    for tuple in combos_to_check:\n",
    "        #all G12s with the desired i value\n",
    "        print(tuple)\n",
    "        G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "        #all edge sets with the desired j value\n",
    "        edge_combos=powerset_dict[tuple[1]]\n",
    "        #iterate through all combos of them\n",
    "        for edges in edge_combos:\n",
    "            for G12 in G12s_to_check:\n",
    "                #create the graph\n",
    "                G13=G12.copy()\n",
    "                G13.add_node(n-1)\n",
    "                G13.add_edges_from(edges)\n",
    "                #count how many we checked\n",
    "                count+=1\n",
    "                k_count+=1\n",
    "                pn_graph = convertNetworkXGraph(G13)\n",
    "                cert = pn.certificate(pn_graph)\n",
    "                if cert not in hash_set_k:\n",
    "                    #if not already checked, add it and check if it is in J4 K5\n",
    "                    hash_set_k.add(cert)\n",
    "                    if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                        #We store if it is in the magical set we are trying to find\n",
    "                        Pj4k5_n13.append(G13)\n",
    "    elapsedk=time.time()-time1\n",
    "    elapsedtotal=time.time()-start_time\n",
    "    print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "    print(str(k_count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "    print(str(len(hash_set_k))+\" unique graphs checked\")\n",
    "    print(str(count)+\" graphs total completed in \"+ str(int(elapsedtotal/6)/10)+\" minutes\")\n",
    "    print(\"Total in P(J4,K5,13) found:\",len(Pj4k5_n13))\n",
    "    #clears the hash set so it frees up space\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1823d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e14_25.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68e936",
   "metadata": {},
   "source": [
    "##### e=26 case, just keep moving. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 26 edges\n",
      "We have 43972115 graphs to check\n",
      "(18, 8)\n",
      "(19, 7)\n",
      "(20, 6)\n",
      "(21, 5)\n",
      "(22, 4)\n",
      "(23, 3)\n",
      "(24, 2)\n",
      "done with graphs with 26 edges\n",
      "43972115 graphs completed in 12430.3 seconds\n",
      "35789966 unique graphs checked\n",
      "43972115 graphs total completed in 207.1 minutes\n",
      "Total in P(J4,K5,13) found: 4008\n"
     ]
    }
   ],
   "source": [
    "#I reset the edge cases, now going to run the code for just e=26\n",
    "Pj4k5_n13=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "k=26\n",
    "print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "#grab all pairs i,j that add to k\n",
    "combos_to_check=combos_dict[k]\n",
    "hash_set_k=set()\n",
    "time1=time.time()\n",
    "#counts the number of graphs with k vertices checked\n",
    "k_count=0\n",
    "How_many_to_check=0\n",
    "for tuple in combos_to_check:\n",
    "    How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "for tuple in combos_to_check:\n",
    "    #all G12s with the desired i value\n",
    "    print(tuple)\n",
    "    G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "    #all edge sets with the desired j value\n",
    "    edge_combos=powerset_dict[tuple[1]]\n",
    "    #iterate through all combos of them\n",
    "    for edges in edge_combos:\n",
    "        for G12 in G12s_to_check:\n",
    "            #create the graph\n",
    "            G13=G12.copy()\n",
    "            G13.add_node(n-1)\n",
    "            G13.add_edges_from(edges)\n",
    "            #count how many we checked\n",
    "            count+=1\n",
    "            k_count+=1\n",
    "            pn_graph = convertNetworkXGraph(G13)\n",
    "            cert = pn.certificate(pn_graph)\n",
    "            if cert not in hash_set_k:\n",
    "                 #if not already checked, add it and check if it is in J4 K5\n",
    "                hash_set_k.add(cert)\n",
    "                if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                    #We store if it is in the magical set we are trying to find\n",
    "                    Pj4k5_n13.append(G13)\n",
    "elapsedk=time.time()-time1\n",
    "elapsedtotal=time.time()-start_time\n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(k_count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(str(len(hash_set_k))+\" unique graphs checked\")\n",
    "print(str(count)+\" graphs total completed in \"+ str(int(elapsedtotal/6)/10)+\" minutes\")\n",
    "print(\"Total in P(J4,K5,13) found:\",len(Pj4k5_n13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ce808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e26.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15230717",
   "metadata": {},
   "source": [
    "##### e=27 case, why not\n",
    "\n",
    "I'm gonna restart the hash set each time we do a new a combo. It will result in some things being checked multiple times, but it will stop the thing from crashing, because the hash set is the thing getting too large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fe64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 27 edges\n",
      "We have 73943353 graphs to check\n",
      "(19, 8)\n",
      "793485\n",
      "(20, 7)\n",
      "3910896\n",
      "(21, 6)\n",
      "12519276\n",
      "(22, 5)\n",
      "23153328\n",
      "(23, 4)\n",
      "21961170\n",
      "(24, 3)\n",
      "9752380\n",
      "(25, 2)\n",
      "1852818\n",
      "done with graphs with 27 edges\n",
      "73943353 graphs completed in 19899.3 seconds\n",
      "Total in P(J4,K5,13,27) found: 8774\n"
     ]
    }
   ],
   "source": [
    "#I reset the edge cases, now going to run the code for just n=27\n",
    "Pj4k5_n13_e27=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "k=27\n",
    "print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "#grab all pairs i,j that add to k\n",
    "combos_to_check=combos_dict[k]\n",
    "time1=time.time()\n",
    "#counts the number of graphs with k vertices checked\n",
    "k_count=0\n",
    "How_many_to_check=0\n",
    "for tuple in combos_to_check:\n",
    "    How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "for tuple in combos_to_check:\n",
    "    #new hash set for each pair\n",
    "    #only save the stuff already in the set\n",
    "    hash_set_k=set(Pj4k5_n13_e27)\n",
    "    #all G12s with the desired i value\n",
    "    print(tuple)\n",
    "    G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "    #all edge sets with the desired j value\n",
    "    edge_combos=powerset_dict[tuple[1]]\n",
    "    #iterate through all combos of them\n",
    "    print(len(G12s_to_check)*len(edge_combos))\n",
    "    for edges in edge_combos:\n",
    "        for G12 in G12s_to_check:\n",
    "            #create the graph\n",
    "            G13=G12.copy()\n",
    "            G13.add_node(n-1)\n",
    "            G13.add_edges_from(edges)\n",
    "            #count how many we checked\n",
    "            count+=1\n",
    "            k_count+=1\n",
    "            pn_graph = convertNetworkXGraph(G13)\n",
    "            cert = pn.certificate(pn_graph)\n",
    "            if cert not in hash_set_k:\n",
    "                 #if not already checked, add it and check if it is in J4 K5\n",
    "                hash_set_k.add(cert)\n",
    "                if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                    #We store if it is in the magical set we are trying to find\n",
    "                    Pj4k5_n13_e27.append(G13)\n",
    "    #clear the hash set\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "#get rid of duplicates\n",
    "Pj4k5_n13_e27=Up_to_isomorphism(Pj4k5_n13_e27)\n",
    "elapsedk=time.time()-time1\n",
    "elapsedtotal=time.time()-start_time\n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(k_count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(\"Total in P(J4,K5,13,27) found:\",len(Pj4k5_n13_e27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e27.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_e27:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be7d80",
   "metadata": {},
   "source": [
    "##### e=28 case\n",
    "\n",
    "Same strategy as e=27.\n",
    "\n",
    "If I can do this case, then I am reasonably confident I can do all of the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32f833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 28 edges\n",
      "We have 104170121 graphs to check\n",
      "(20, 8)\n",
      "2444310\n",
      "(21, 7)\n",
      "10730808\n",
      "(22, 6)\n",
      "27012216\n",
      "(23, 5)\n",
      "35137872\n",
      "(24, 4)\n",
      "21942855\n",
      "(25, 3)\n",
      "6176060\n",
      "(26, 2)\n",
      "726000\n",
      "done with graphs with 28 edges\n",
      "104170121 graphs completed in 29677.3 seconds\n",
      "Total in P(J4,K5,13,28) found: 12235\n"
     ]
    }
   ],
   "source": [
    "#I reset the edge cases, now going to run the code for just n=28\n",
    "Pj4k5_n13_e28=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "k=28\n",
    "print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "#grab all pairs i,j that add to k\n",
    "combos_to_check=combos_dict[k]\n",
    "time1=time.time()\n",
    "#counts the number of graphs with k vertices checked\n",
    "k_count=0\n",
    "How_many_to_check=0\n",
    "for tuple in combos_to_check:\n",
    "    How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "for tuple in combos_to_check:\n",
    "    #new hash set for each pair\n",
    "    #only save the stuff already in the set\n",
    "    hash_set_k=set(Pj4k5_n13_e28)\n",
    "    #all G12s with the desired i value\n",
    "    print(tuple)\n",
    "    G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "    #all edge sets with the desired j value\n",
    "    edge_combos=powerset_dict[tuple[1]]\n",
    "    #iterate through all combos of them\n",
    "    print(len(G12s_to_check)*len(edge_combos))\n",
    "    for edges in edge_combos:\n",
    "        for G12 in G12s_to_check:\n",
    "            #create the graph\n",
    "            G13=G12.copy()\n",
    "            G13.add_node(n-1)\n",
    "            G13.add_edges_from(edges)\n",
    "            #count how many we checked\n",
    "            count+=1\n",
    "            k_count+=1\n",
    "            pn_graph = convertNetworkXGraph(G13)\n",
    "            cert = pn.certificate(pn_graph)\n",
    "            if cert not in hash_set_k:\n",
    "                 #if not already checked, add it and check if it is in J4 K5\n",
    "                hash_set_k.add(cert)\n",
    "                if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                    #We store if it is in the magical set we are trying to find\n",
    "                    Pj4k5_n13_e28.append(G13)\n",
    "    #clear the hash set\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "#get rid of duplicates(just in case)\n",
    "Pj4k5_n13_e28=Up_to_isomorphism(Pj4k5_n13_e28)\n",
    "elapsedk=time.time()-time1\n",
    "elapsedtotal=time.time()-start_time\n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(k_count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(\"Total in P(J4,K5,13,28) found:\",len(Pj4k5_n13_e28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda93ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e28.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_e28:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4dc4d",
   "metadata": {},
   "source": [
    "##### e=29 case\n",
    "\n",
    "This is the biggest case, so if we get past it, we are gonna get through this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adefe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 29 edges\n",
      "We have 122450504 graphs to check\n",
      "(21, 8)\n",
      "6706755\n",
      "(22, 7)\n",
      "23153328\n",
      "(23, 6)\n",
      "40994184\n",
      "(24, 5)\n",
      "35108568\n",
      "(25, 4)\n",
      "13896135\n",
      "(26, 3)\n",
      "2420000\n",
      "(27, 2)\n",
      "171534\n",
      "done with graphs with 29 edges\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m elapsedtotal\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone with graphs with \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(k)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m edges\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[43mk_count\u001b[49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m graphs completed in \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39melapsedk)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal in P(J4,K5,13,29) found:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(Pj4k5_n13_e29))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k_count' is not defined"
     ]
    }
   ],
   "source": [
    "#I reset the edge cases, now going to run the code for just n=29\n",
    "Pj4k5_n13_e29=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "k=29\n",
    "print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "#grab all pairs i,j that add to k\n",
    "combos_to_check=combos_dict[k]\n",
    "time1=time.time()\n",
    "How_many_to_check=0\n",
    "for tuple in combos_to_check:\n",
    "    How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "for tuple in combos_to_check:\n",
    "    #new hash set for each pair\n",
    "    hash_set_k=set()\n",
    "    #all G12s with the desired i value\n",
    "    print(tuple)\n",
    "    G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "    #all edge sets with the desired j value\n",
    "    edge_combos=powerset_dict[tuple[1]]\n",
    "    #iterate through all combos of them\n",
    "    print(len(G12s_to_check)*len(edge_combos))\n",
    "    for edges in edge_combos:\n",
    "        for G12 in G12s_to_check:\n",
    "            #create the graph\n",
    "            G13=G12.copy()\n",
    "            G13.add_node(n-1)\n",
    "            G13.add_edges_from(edges)\n",
    "            #count how many we checked\n",
    "            count+=1\n",
    "            pn_graph = convertNetworkXGraph(G13)\n",
    "            cert = pn.certificate(pn_graph)\n",
    "            if cert not in hash_set_k:\n",
    "                 #if not already checked, add it and check if it is in J4 K5\n",
    "                hash_set_k.add(cert)\n",
    "                if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                    #We store if it is in the magical set we are trying to find\n",
    "                    Pj4k5_n13_e29.append(G13)\n",
    "    #clear the hash set\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "#get rid of duplicates\n",
    "Pj4k5_n13_e29=Up_to_isomorphism(Pj4k5_n13_e29)\n",
    "elapsedk=time.time()-time1\n",
    "elapsedtotal=time.time()-start_time\n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(\"Total in P(J4,K5,13,29) found:\",len(Pj4k5_n13_e29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ef448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with graphs with 29 edges\n",
      "122450504 graphs completed in 34104.3 seconds\n",
      "Total in P(J4,K5,13,29) found: 10903\n"
     ]
    }
   ],
   "source": [
    "#The error above didn't break anything, it was just the print statement at the end that I messed up\n",
    "#this is the fixed version \n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(\"Total in P(J4,K5,13,29) found:\",len(Pj4k5_n13_e29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e29.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_e29:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb030d",
   "metadata": {},
   "source": [
    "##### e=30 case! We got this!\n",
    "\n",
    "The largest case was that last e=29 case, so we are in the home stretch for n=13. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 30 edges\n",
      "We have 118843384 graphs to check\n",
      "(22, 8)\n",
      "14470830\n",
      "(23, 7)\n",
      "35137872\n",
      "(24, 6)\n",
      "40959996\n",
      "(25, 5)\n",
      "22233816\n",
      "(26, 4)\n",
      "5445000\n",
      "(27, 3)\n",
      "571780\n",
      "(28, 2)\n",
      "24090\n",
      "done with graphs with 30 edges\n",
      "118843384 graphs completed in 34946.9 seconds\n",
      "Total in P(J4,K5,13,30) found: 6246\n"
     ]
    }
   ],
   "source": [
    "#I reset the edge cases, now going to run the code for just n=30\n",
    "Pj4k5_n13_e30=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "k=30\n",
    "print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "#grab all pairs i,j that add to k\n",
    "combos_to_check=combos_dict[k]\n",
    "time1=time.time()\n",
    "How_many_to_check=0\n",
    "for tuple in combos_to_check:\n",
    "    How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "for tuple in combos_to_check:\n",
    "    #new hash set for each pair\n",
    "    hash_set_k=set()\n",
    "    #all G12s with the desired i value\n",
    "    print(tuple)\n",
    "    G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "    #all edge sets with the desired j value\n",
    "    edge_combos=powerset_dict[tuple[1]]\n",
    "    #iterate through all combos of them\n",
    "    print(len(G12s_to_check)*len(edge_combos))\n",
    "    for edges in edge_combos:\n",
    "        for G12 in G12s_to_check:\n",
    "            #create the graph\n",
    "            G13=G12.copy()\n",
    "            G13.add_node(n-1)\n",
    "            G13.add_edges_from(edges)\n",
    "            #count how many we checked\n",
    "            count+=1\n",
    "            pn_graph = convertNetworkXGraph(G13)\n",
    "            cert = pn.certificate(pn_graph)\n",
    "            if cert not in hash_set_k:\n",
    "                 #if not already checked, add it and check if it is in J4 K5\n",
    "                hash_set_k.add(cert)\n",
    "                if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                    #We store if it is in the magical set we are trying to find\n",
    "                    Pj4k5_n13_e30.append(G13)\n",
    "    #clear the hash set\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "#get rid of duplicates\n",
    "Pj4k5_n13_e30=Up_to_isomorphism(Pj4k5_n13_e30)\n",
    "elapsedk=time.time()-time1\n",
    "elapsedtotal=time.time()-start_time\n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(f\"Total in P(J4,K5,13,{str(k)}) found:\",len(Pj4k5_n13_e30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1415321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e30.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_e30:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aad293",
   "metadata": {},
   "source": [
    "##### e=31 case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2bafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 31 edges\n",
      "We have 93089909 graphs to check\n",
      "(23, 8)\n",
      "21961170\n",
      "(24, 7)\n",
      "35108568\n",
      "(25, 6)\n",
      "25939452\n",
      "(26, 5)\n",
      "8712000\n",
      "(27, 4)\n",
      "1286505\n",
      "(28, 3)\n",
      "80300\n",
      "(29, 2)\n",
      "1914\n",
      "done with graphs with 31 edges\n",
      "93089909 graphs completed in 25342.7 seconds\n",
      "Total in P(J4,K5,13,31) found: 2271\n"
     ]
    }
   ],
   "source": [
    "#I reset the edge cases, now going to run the code for just n=31\n",
    "Pj4k5_n13_e31=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "k=31\n",
    "print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "#grab all pairs i,j that add to k\n",
    "combos_to_check=combos_dict[k]\n",
    "time1=time.time()\n",
    "How_many_to_check=0\n",
    "for tuple in combos_to_check:\n",
    "    How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "for tuple in combos_to_check:\n",
    "    #new hash set for each pair\n",
    "    hash_set_k=set()\n",
    "    #all G12s with the desired i value\n",
    "    print(tuple)\n",
    "    G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "    #all edge sets with the desired j value\n",
    "    edge_combos=powerset_dict[tuple[1]]\n",
    "    #iterate through all combos of them\n",
    "    print(len(G12s_to_check)*len(edge_combos))\n",
    "    for edges in edge_combos:\n",
    "        for G12 in G12s_to_check:\n",
    "            #create the graph\n",
    "            G13=G12.copy()\n",
    "            G13.add_node(n-1)\n",
    "            G13.add_edges_from(edges)\n",
    "            #count how many we checked\n",
    "            count+=1\n",
    "            pn_graph = convertNetworkXGraph(G13)\n",
    "            cert = pn.certificate(pn_graph)\n",
    "            if cert not in hash_set_k:\n",
    "                 #if not already checked, add it and check if it is in J4 K5\n",
    "                hash_set_k.add(cert)\n",
    "                if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                    #We store if it is in the magical set we are trying to find\n",
    "                    Pj4k5_n13_e31.append(G13)\n",
    "    #clear the hash set\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "#get rid of duplicates\n",
    "Pj4k5_n13_e31=Up_to_isomorphism(Pj4k5_n13_e31)\n",
    "elapsedk=time.time()-time1\n",
    "elapsedtotal=time.time()-start_time\n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(f\"Total in P(J4,K5,13,{str(k)}) found:\",len(Pj4k5_n13_e31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e31.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_e31:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc991b",
   "metadata": {},
   "source": [
    "##### e=32 case\n",
    "\n",
    "This is the last one we need to do individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfc80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 32 edges\n",
      "We have 56586398 graphs to check\n",
      "(24, 8)\n",
      "21942855\n",
      "(25, 7)\n",
      "22233816\n",
      "(26, 6)\n",
      "10164000\n",
      "(27, 5)\n",
      "2058408\n",
      "(28, 4)\n",
      "180675\n",
      "(29, 3)\n",
      "6380\n",
      "(30, 2)\n",
      "264\n",
      "done with graphs with 32 edges\n",
      "56586398 graphs completed in 15569.4 seconds\n",
      "Total in P(J4,K5,13,32) found: 518\n"
     ]
    }
   ],
   "source": [
    "#I reset the edge cases, now going to run the code for just n=32\n",
    "Pj4k5_n13_e32=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "k=32\n",
    "print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "#grab all pairs i,j that add to k\n",
    "combos_to_check=combos_dict[k]\n",
    "time1=time.time()\n",
    "How_many_to_check=0\n",
    "for tuple in combos_to_check:\n",
    "    How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "for tuple in combos_to_check:\n",
    "    #new hash set for each pair\n",
    "    hash_set_k=set()\n",
    "    #all G12s with the desired i value\n",
    "    print(tuple)\n",
    "    G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "    #all edge sets with the desired j value\n",
    "    edge_combos=powerset_dict[tuple[1]]\n",
    "    #iterate through all combos of them\n",
    "    print(len(G12s_to_check)*len(edge_combos))\n",
    "    for edges in edge_combos:\n",
    "        for G12 in G12s_to_check:\n",
    "            #create the graph\n",
    "            G13=G12.copy()\n",
    "            G13.add_node(n-1)\n",
    "            G13.add_edges_from(edges)\n",
    "            #count how many we checked\n",
    "            count+=1\n",
    "            pn_graph = convertNetworkXGraph(G13)\n",
    "            cert = pn.certificate(pn_graph)\n",
    "            if cert not in hash_set_k:\n",
    "                 #if not already checked, add it and check if it is in J4 K5\n",
    "                hash_set_k.add(cert)\n",
    "                if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                    #We store if it is in the magical set we are trying to find\n",
    "                    Pj4k5_n13_e32.append(G13)\n",
    "    #clear the hash set\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "#get rid of duplicates\n",
    "Pj4k5_n13_e32=Up_to_isomorphism(Pj4k5_n13_e32)\n",
    "elapsedk=time.time()-time1\n",
    "elapsedtotal=time.time()-start_time\n",
    "print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "print(str(count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "print(f\"Total in P(J4,K5,13,{str(k)}) found:\",len(Pj4k5_n13_e32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e32.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_e32:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4892df96",
   "metadata": {},
   "source": [
    "##### e=33-38, last cases\n",
    "\n",
    "Just finishing this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe8b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 33 edges\n",
      "We have 25313926 graphs to check\n",
      "(25, 8)\n",
      "(26, 7)\n",
      "(27, 6)\n",
      "(28, 5)\n",
      "(29, 4)\n",
      "(30, 3)\n",
      "done with graphs with 33 edges\n",
      "25313926 graphs completed in 6813.5 seconds\n",
      "24311531 unique graphs checked\n",
      "25313926 graphs total completed in 113.5 minutes\n",
      "Total in P(J4,K5,13,33-38) found: 69\n",
      "\n",
      "Now checking graphs with 34 edges\n",
      "We have 7865616 graphs to check\n",
      "(26, 8)\n",
      "(27, 7)\n",
      "(28, 6)\n",
      "(29, 5)\n",
      "(30, 4)\n",
      "done with graphs with 34 edges\n",
      "7865616 graphs completed in 2175.4 seconds\n",
      "7440356 unique graphs checked\n",
      "33179542 graphs total completed in 150.1 minutes\n",
      "Total in P(J4,K5,13,33-38) found: 76\n",
      "\n",
      "Now checking graphs with 35 edges\n",
      "We have 1605549 graphs to check\n",
      "(27, 8)\n",
      "(28, 7)\n",
      "(29, 6)\n",
      "(30, 5)\n",
      "done with graphs with 35 edges\n",
      "1605549 graphs completed in 424.0 seconds\n",
      "1455530 unique graphs checked\n",
      "34785091 graphs total completed in 157.4 minutes\n",
      "Total in P(J4,K5,13,33-38) found: 76\n",
      "\n",
      "Now checking graphs with 36 edges\n",
      "We have 207339 graphs to check\n",
      "(28, 8)\n",
      "(29, 7)\n",
      "(30, 6)\n",
      "done with graphs with 36 edges\n",
      "207339 graphs completed in 52.4 seconds\n",
      "166378 unique graphs checked\n",
      "34992430 graphs total completed in 158.4 minutes\n",
      "Total in P(J4,K5,13,33-38) found: 76\n",
      "\n",
      "Now checking graphs with 37 edges\n",
      "We have 17523 graphs to check\n",
      "(29, 8)\n",
      "(30, 7)\n",
      "done with graphs with 37 edges\n",
      "17523 graphs completed in 3.8 seconds\n",
      "9513 unique graphs checked\n",
      "35009953 graphs total completed in 158.5 minutes\n",
      "Total in P(J4,K5,13,33-38) found: 76\n",
      "\n",
      "Now checking graphs with 38 edges\n",
      "We have 1980 graphs to check\n",
      "(30, 8)\n",
      "done with graphs with 38 edges\n",
      "1980 graphs completed in 0.3 seconds\n",
      "208 unique graphs checked\n",
      "35011933 graphs total completed in 158.6 minutes\n",
      "Total in P(J4,K5,13,33-38) found: 76\n"
     ]
    }
   ],
   "source": [
    "#run through 33-38\n",
    "Pj4k5_n13_e33_38=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "for k in range(33,39):\n",
    "    print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "    #grab all pairs i,j that add to k\n",
    "    combos_to_check=combos_dict[k]\n",
    "    hash_set_k=set()\n",
    "    time1=time.time()\n",
    "    #counts the number of graphs with k vertices checked\n",
    "    k_count=0\n",
    "    How_many_to_check=0\n",
    "    for tuple in combos_to_check:\n",
    "        How_many_to_check+=len(Pj4k5_n12_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "    print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "    for tuple in combos_to_check:\n",
    "        #all G12s with the desired i value\n",
    "        print(tuple)\n",
    "        G12s_to_check=Pj4k5_n12_dict[tuple[0]]\n",
    "        #all edge sets with the desired j value\n",
    "        edge_combos=powerset_dict[tuple[1]]\n",
    "        #iterate through all combos of them\n",
    "        for edges in edge_combos:\n",
    "            for G12 in G12s_to_check:\n",
    "                #create the graph\n",
    "                G13=G12.copy()\n",
    "                G13.add_node(n-1)\n",
    "                G13.add_edges_from(edges)\n",
    "                #count how many we checked\n",
    "                count+=1\n",
    "                k_count+=1\n",
    "                pn_graph = convertNetworkXGraph(G13)\n",
    "                cert = pn.certificate(pn_graph)\n",
    "                if cert not in hash_set_k:\n",
    "                    #if not already checked, add it and check if it is in J4 K5\n",
    "                    hash_set_k.add(cert)\n",
    "                    if not ContainsJ4(G13) and not ContainsAntiK5(G13):\n",
    "                        #We store if it is in the magical set we are trying to find\n",
    "                        Pj4k5_n13_e33_38.append(G13)\n",
    "    elapsedk=time.time()-time1\n",
    "    elapsedtotal=time.time()-start_time\n",
    "    print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "    print(str(k_count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "    print(str(len(hash_set_k))+\" unique graphs checked\")\n",
    "    print(str(count)+\" graphs total completed in \"+ str(int(elapsedtotal/6)/10)+\" minutes\")\n",
    "    print(\"Total in P(J4,K5,13,33-38) found:\",len(Pj4k5_n13_e33_38))\n",
    "    #clears the hash set so it frees up space\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c45681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the partial census we have completed\n",
    "#So we can clear things and deal with individual cases\n",
    "with open(\"Pj4k5n13e33_38.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_e33_38:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb0df6",
   "metadata": {},
   "source": [
    "##### Combine it into one text file\n",
    "\n",
    "I just want it to be available all one txt file. So I will load them all in and recombine them now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1808ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "Pj4k5_n13_e14_25=nx.read_graph6(\"Pj4k5n13e14_25.txt\")\n",
    "Pj4k5_n13_e26=nx.read_graph6(\"Pj4k5n13e26.txt\")\n",
    "Pj4k5_n13_e27=nx.read_graph6(\"Pj4k5n13e27.txt\")\n",
    "Pj4k5_n13_e28=nx.read_graph6(\"Pj4k5n13e28.txt\")\n",
    "Pj4k5_n13_e29=nx.read_graph6(\"Pj4k5n13e29.txt\")\n",
    "Pj4k5_n13_e30=nx.read_graph6(\"Pj4k5n13e30.txt\")\n",
    "Pj4k5_n13_e31=nx.read_graph6(\"Pj4k5n13e31.txt\")\n",
    "Pj4k5_n13_e32=nx.read_graph6(\"Pj4k5n13e32.txt\")\n",
    "Pj4k5_n13_e33_38=nx.read_graph6(\"Pj4k5n13e33_38.txt\")\n",
    "Pj4k5_n13_final=Pj4k5_n13_e14_25+Pj4k5_n13_e26+Pj4k5_n13_e27+Pj4k5_n13_e28+Pj4k5_n13_e29+Pj4k5_n13_e30+Pj4k5_n13_e31+Pj4k5_n13_e32+Pj4k5_n13_e33_38\n",
    "with open(\"Pj4k5n13.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n13_final:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1e204",
   "metadata": {},
   "source": [
    "#### n=14 case! \n",
    "\n",
    "325,895,570 cases to check. Time to plug along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9b4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in n=13\n",
    "#restarted the kernel to clear cache\n",
    "Pj4k5_n13=nx.read_graph6(\"Pj4k5n13.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc26ce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{32, 33, 34, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31}\n"
     ]
    }
   ],
   "source": [
    "#Sort Pj4k5_n13 by edge count\n",
    "\n",
    "#First, we need to identify the possible edge counts for n=13\n",
    "thirteen_hash=set()\n",
    "for graph in Pj4k5_n13:\n",
    "    edge_count=len(graph.edges())\n",
    "    if edge_count not in thirteen_hash:\n",
    "        thirteen_hash.add(edge_count)\n",
    "print(thirteen_hash)\n",
    "#Next, we sort into a dictionary by edge count\n",
    "Pj4k5_n13_dict={k:[] for k in thirteen_hash}\n",
    "for graph in Pj4k5_n13:\n",
    "    k=len(graph.edges())\n",
    "    Pj4k5_n13_dict[k].append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4415d8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{24: [(21, 3)], 25: [(21, 4), (22, 3)], 26: [(21, 5), (22, 4), (23, 3)], 27: [(21, 6), (22, 5), (23, 4), (24, 3)], 28: [(21, 7), (22, 6), (23, 5), (24, 4), (25, 3)], 29: [(21, 8), (22, 7), (23, 6), (24, 5), (25, 4), (26, 3)], 30: [(22, 8), (23, 7), (24, 6), (25, 5), (26, 4), (27, 3)], 31: [(23, 8), (24, 7), (25, 6), (26, 5), (27, 4), (28, 3)], 32: [(24, 8), (25, 7), (26, 6), (27, 5), (28, 4), (29, 3)], 33: [(25, 8), (26, 7), (27, 6), (28, 5), (29, 4), (30, 3)], 34: [(26, 8), (27, 7), (28, 6), (29, 5), (30, 4), (31, 3)], 35: [(32, 3), (27, 8), (28, 7), (29, 6), (30, 5), (31, 4)], 36: [(32, 4), (33, 3), (28, 8), (29, 7), (30, 6), (31, 5)], 37: [(32, 5), (33, 4), (34, 3), (29, 8), (30, 7), (31, 6)], 38: [(32, 6), (33, 5), (34, 4), (30, 8), (31, 7)], 39: [(32, 7), (33, 6), (34, 5), (31, 8)], 40: [(32, 8), (33, 7), (34, 6)], 41: [(33, 8), (34, 7)], 42: [(34, 8)]}\n",
      "24 286\n",
      "25 2431\n",
      "26 15873\n",
      "27 105248\n",
      "28 574145\n",
      "29 2386527\n",
      "30 7397819\n",
      "31 17441424\n",
      "32 32395220\n",
      "33 48795175\n",
      "34 60357297\n",
      "35 60807461\n",
      "36 48487010\n",
      "37 29365336\n",
      "38 12918334\n",
      "39 3939078\n",
      "40 797082\n",
      "41 100815\n",
      "42 9009\n"
     ]
    }
   ],
   "source": [
    "#Now, sort the powerset by how many edges it adds to the G14\n",
    "n=14\n",
    "Possible_Edges=[(n-1,k) for k in range(n-1)]\n",
    "#lower bound is now 3\n",
    "powerset13=powerset(Possible_Edges,upper_bound=8,lower_bound=3)\n",
    "#sort into a dictionary by # of edges added\n",
    "powerset_dict={k:[] for k in range(3,9)} \n",
    "for edges in powerset13:\n",
    "    powerset_dict[len(edges)].append(edges)\n",
    "\n",
    "#There are 21-34 edged graphs in the G13, and 3-8 being added, so we will be checking graphs with 24 to 42 edges\n",
    "#for each possible number k for e(G14), we will only check graphs constructed with numbers that sum to k\n",
    "\n",
    "#Now, for each possible edge count for a G13, we will make a list of tuples \n",
    "# that indicated what combos add to that edge count\n",
    "#so for 24 we have [(21,3)], for 25 we have [(22,3),(21,4)], etc\n",
    "combos_dict={k:[] for k in range(24,43)}\n",
    "for G13_size in thirteen_hash:\n",
    "    for edges_size in range(3,9):\n",
    "        combos_dict[G13_size+edges_size].append((G13_size,edges_size))\n",
    "\n",
    "print(combos_dict)\n",
    "\n",
    "#Counting which cases will be the worst to do\n",
    "for k in combos_dict:\n",
    "    count3=0\n",
    "    for tuple in combos_dict[k]:\n",
    "        count3+=len(Pj4k5_n13_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "    print(k,count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf8b348",
   "metadata": {},
   "source": [
    "##### e=24-32 case\n",
    "\n",
    "The only edge cases that I don't want to run with the rest are 33 to 36. So we get the first 9 cases out of the way quickly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce6a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now checking graphs with 24 edges\n",
      "We have 286 graphs to check\n",
      "(21, 3)\n",
      "done with graphs with 24 edges\n",
      "286 graphs completed in 0.0 seconds\n",
      "30 unique graphs checked\n",
      "286 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 0\n",
      "\n",
      "Now checking graphs with 25 edges\n",
      "We have 2431 graphs to check\n",
      "(21, 4)\n",
      "(22, 3)\n",
      "done with graphs with 25 edges\n",
      "2431 graphs completed in 1.0 seconds\n",
      "479 unique graphs checked\n",
      "2717 graphs total completed in 0.0 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 0\n",
      "\n",
      "Now checking graphs with 26 edges\n",
      "We have 15873 graphs to check\n",
      "(21, 5)\n",
      "(22, 4)\n",
      "(23, 3)\n",
      "done with graphs with 26 edges\n",
      "15873 graphs completed in 4.9 seconds\n",
      "6463 unique graphs checked\n",
      "18590 graphs total completed in 0.1 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 0\n",
      "\n",
      "Now checking graphs with 27 edges\n",
      "We have 105248 graphs to check\n",
      "(21, 6)\n",
      "(22, 5)\n",
      "(23, 4)\n",
      "(24, 3)\n",
      "done with graphs with 27 edges\n",
      "105248 graphs completed in 35.1 seconds\n",
      "65547 unique graphs checked\n",
      "123838 graphs total completed in 0.7 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 0\n",
      "\n",
      "Now checking graphs with 28 edges\n",
      "We have 574145 graphs to check\n",
      "(21, 7)\n",
      "(22, 6)\n",
      "(23, 5)\n",
      "(24, 4)\n",
      "(25, 3)\n",
      "done with graphs with 28 edges\n",
      "574145 graphs completed in 198.6 seconds\n",
      "443207 unique graphs checked\n",
      "697983 graphs total completed in 4.0 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 2\n",
      "\n",
      "Now checking graphs with 29 edges\n",
      "We have 2386527 graphs to check\n",
      "(21, 8)\n",
      "(22, 7)\n",
      "(23, 6)\n",
      "(24, 5)\n",
      "(25, 4)\n",
      "(26, 3)\n",
      "done with graphs with 29 edges\n",
      "2386527 graphs completed in 786.1 seconds\n",
      "2025128 unique graphs checked\n",
      "3084510 graphs total completed in 17.1 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 6\n",
      "\n",
      "Now checking graphs with 30 edges\n",
      "We have 7397819 graphs to check\n",
      "(22, 8)\n",
      "(23, 7)\n",
      "(24, 6)\n",
      "(25, 5)\n",
      "(26, 4)\n",
      "(27, 3)\n",
      "done with graphs with 30 edges\n",
      "7397819 graphs completed in 2339.6 seconds\n",
      "6553260 unique graphs checked\n",
      "10482329 graphs total completed in 56.1 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 18\n",
      "\n",
      "Now checking graphs with 31 edges\n",
      "We have 17441424 graphs to check\n",
      "(23, 8)\n",
      "(24, 7)\n",
      "(25, 6)\n",
      "(26, 5)\n",
      "(27, 4)\n",
      "(28, 3)\n",
      "done with graphs with 31 edges\n",
      "17441424 graphs completed in 5257.6 seconds\n",
      "15800125 unique graphs checked\n",
      "27923753 graphs total completed in 143.8 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 53\n",
      "\n",
      "Now checking graphs with 32 edges\n",
      "We have 32395220 graphs to check\n",
      "(24, 8)\n",
      "(25, 7)\n",
      "(26, 6)\n",
      "(27, 5)\n",
      "(28, 4)\n",
      "(29, 3)\n",
      "done with graphs with 32 edges\n",
      "32395220 graphs completed in 9950.9 seconds\n",
      "29789466 unique graphs checked\n",
      "60318973 graphs total completed in 309.8 minutes\n",
      "Total in P(J4,K5,14,24-32) found: 131\n"
     ]
    }
   ],
   "source": [
    "#run through 24-32\n",
    "Pj4k5_n14_e24_32=[]\n",
    "count=0\n",
    "start_time=time.time()\n",
    "for k in range(24,33):\n",
    "    print(chr(10)+\"Now checking graphs with \"+str(k)+\" edges\")\n",
    "    #grab all pairs i,j that add to k\n",
    "    combos_to_check=combos_dict[k]\n",
    "    hash_set_k=set()\n",
    "    time1=time.time()\n",
    "    #counts the number of graphs with k vertices checked\n",
    "    k_count=0\n",
    "    How_many_to_check=0\n",
    "    for tuple in combos_to_check:\n",
    "        How_many_to_check+=len(Pj4k5_n13_dict[tuple[0]])*len(powerset_dict[tuple[1]])\n",
    "    print(\"We have\",How_many_to_check, \"graphs to check\")\n",
    "    for tuple in combos_to_check:\n",
    "        #all G12s with the desired i value\n",
    "        print(tuple)\n",
    "        G13s_to_check=Pj4k5_n13_dict[tuple[0]]\n",
    "        #all edge sets with the desired j value\n",
    "        edge_combos=powerset_dict[tuple[1]]\n",
    "        #iterate through all combos of them\n",
    "        for edges in edge_combos:\n",
    "            for G13 in G13s_to_check:\n",
    "                #create the graph\n",
    "                G14=G13.copy()\n",
    "                G14.add_node(n-1)\n",
    "                G14.add_edges_from(edges)\n",
    "                #count how many we checked\n",
    "                count+=1\n",
    "                k_count+=1\n",
    "                pn_graph = convertNetworkXGraph(G14)\n",
    "                cert = pn.certificate(pn_graph)\n",
    "                if cert not in hash_set_k:\n",
    "                    #if not already checked, add it and check if it is in J4 K5\n",
    "                    hash_set_k.add(cert)\n",
    "                    if not ContainsJ4(G14) and not ContainsAntiK5(G14):\n",
    "                        #We store if it is in the magical set we are trying to find\n",
    "                        Pj4k5_n14_e24_32.append(G14)\n",
    "    elapsedk=time.time()-time1\n",
    "    elapsedtotal=time.time()-start_time\n",
    "    print(\"done with graphs with \"+str(k)+\" edges\")\n",
    "    print(str(k_count)+\" graphs completed in \"+str(int(10*elapsedk)/10)+\" seconds\")\n",
    "    print(str(len(hash_set_k))+\" unique graphs checked\")\n",
    "    print(str(count)+\" graphs total completed in \"+ str(int(elapsedtotal/6)/10)+\" minutes\")\n",
    "    print(\"Total in P(J4,K5,14,24-32) found:\",len(Pj4k5_n14_e24_32))\n",
    "    #clears the hash set so it frees up space\n",
    "    del hash_set_k\n",
    "    gc.collect()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fed0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save this partial census\n",
    "with open(\"Pj4k5n14e24_32.txt\",\"wb\") as f:\n",
    "    for graph in Pj4k5_n14_e24_32:\n",
    "      nx.write_graph6(graph,f,header=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
